{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2 Fundamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilidad:** $\\;$ La función de densidad de la Gaussiana $D$-dimensional es de la forma\n",
    "$$p(\\boldsymbol{y}\\mid\\boldsymbol{\\mu},\\mathbf{\\Sigma})=\\dfrac{1}{(2\\pi)^{D/2}\\det{\\mathbf{\\Sigma}}^{1/2}}%\n",
    "\\exp\\left[-\\dfrac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\mu})^t\\mathbf{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{\\mu})\\right], %\n",
    "\\quad\\boldsymbol{\\mu}\\mathbb{I}n\\mathbb{R}^D,\\;\\mathbf{\\Sigma}\\mathbb{I}n\\mathbb{R}^{D\\times D},\\;\\mathbf{\\Sigma}\\succeq 0$$\n",
    "Sus conjuntos de nivel son proporcionales a los de la distancia de Mahalanobis entre $\\boldsymbol{y}$ y $\\boldsymbol{\\mu}$. La forma de estos conjuntos, esto es, de la bola Gaussiana centrada en $\\boldsymbol{\\mu}$, depende de $\\mathbf{\\Sigma}$. Suponiendo que $D=2$, indica la respuesta incorrecta (o la última opción si las tres primeras son correctas).\n",
    "1. Si $\\mathbf{\\Sigma}=\\sigma^2\\mathbf{I}$, la Gaussiana es circular.\n",
    "2. Si $\\mathbf{\\Sigma}$ es diagonal, la Gaussiana es rectangular.\n",
    "3. Si $\\mathbf{\\Sigma}$ no es diagonal (con elementos no nulos fuera de la diagonal), la Gaussiana es elípitica.\n",
    "4. Las tres opciones anteriores son correctas.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 2; la Gaussiana es elípitica, de semiejes alineados con los canónicos.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadística:** $\\;$ Sea $\\,\\mathcal{D}=\\{(\\boldsymbol{x}_n,\\boldsymbol{y}_n)\\}_{n=1}^N\\,$ un conjunto de datos y sea $\\,p(\\mathcal{D}\\mid\\boldsymbol{\\theta})\\,$ la verosimilitud de un modelo gobernado por un vector de parámetros $\\,\\boldsymbol{\\theta}$. Supón que la verosimilitud puede factorizarse de manera naive como $p(\\mathcal{D}\\mid\\boldsymbol{\\theta})=\\prod_n p(\\boldsymbol{y}_n\\mid\\boldsymbol{x}_n,\\boldsymbol{\\theta})$. Con base en esta asunción, se quiere hallar un estimador máximo-verosímil de $\\boldsymbol{\\theta}$, $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}$. Indica la respuesta incorrecta (o la última opción si las tres primeras son correctas).\n",
    "1. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{x}_n,\\boldsymbol{\\theta})$\n",
    "2. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{x}_n, \\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})-\\log p(\\boldsymbol{x}_n\\mid\\boldsymbol{\\theta})$\n",
    "3. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{x}_n, \\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})$\n",
    "4. Las tres opciones anteriores son correctas.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 3.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadística:** $\\;$ Uno de los grandes retos del aprendizaje automático consiste en aprender modelos que generalicen bien, esto es, que no se limiten a predecir correctamente los datos de entrenamiento, sino que también predigan bien datos futuros. Con el fin de afrontar este reto, se suelen seguir varias estrategias convencionales que por lo general dan buen resultado. Indica cuál de las siguientes estrategias **no** es una estrategia convencional para generalizar mejor (o escoge la última opción si las tres primeras sí lo son).\n",
    "1. Regularización.\n",
    "2. Terminación temprana (asumiendo que se usa un algoritmo de aprendizaje iterativo).\n",
    "3. Uso de más datos.\n",
    "4. Las tres opciones anteriores son estrategias convencionales para generalizar mejor.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 4.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decisión:** $\\;$ En un problema de clasificación en $C$ clases, tanto los posibles estados de la naturaleza como las posibles acciones son etiquetas de clase, $\\,\\mathcal{H}=\\mathcal{A}=\\mathcal{Y}=\\{1,\\dotsc,C\\}$. Supón que la pérdida asociada a cada par estado-acción es la 01, $\\,\\ell(y^*,\\hat{y})=\\mathbb{I}(y^*\\neq\\hat{y}),\\,$ donde $\\,y^*\\,$ denota la clase verdadera y $\\hat{y}$ la predicha. Dada una observación $\\boldsymbol{x}$, el riesgo de una acción $\\,\\hat{y}\\,$ y la acción de mínimo riesgo (regla de Bayes) son:\n",
    "1. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*=\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmin}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "2. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*=\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "3. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*\\neq\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmin}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "4. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*\\neq\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 2.</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
