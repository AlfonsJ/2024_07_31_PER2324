{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T2 Fundamentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Algebra:** $\\;$ Obtén una descomposición propia de la matriz de varianzas $\\,\\mathbf{\\Sigma}=\\begin{pmatrix}9&0\\\\0&4\\end{pmatrix}$.\n",
    "\n",
    "<details><summary>Solución:</summary><br>\n",
    "\n",
    "$$\\begin{align*}\n",
    "\\mathbf{\\Sigma}&=\\mathbf{U}\\mathbf{\\Lambda}\\mathbf{U}^t%\n",
    "\\quad\\text{con}\\quad%\n",
    "\\mathbf{U}=\\mathbf{I}%\n",
    "\\quad\\text{y}\\quad%\n",
    "\\mathbf{\\Lambda}=\\operatorname{diag}(9, 4)\\\\[3mm]%\n",
    "% \\bW_{\\text{pca}}&=\\mathbf{\\Lambda}^{-1/2}\\mathbf{U}^t%\n",
    "% =\\operatorname{diag}(1/3, 1/2)\n",
    "\\end{align*}$$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización:** $\\;$ La estimación de parámetros en aprendizaje automático requiere resolver un **problema de optimización** que por lo general se plantea en términos de **minimización.** La función objetivo, $\\,\\mathcal{L}(\\boldsymbol{\\theta}),\\,$  toma un vector de $D$ parámetros, $\\,\\boldsymbol{\\theta}\\in\\mathbb{R}^D,\\,$ y devuelve la **pérdida o coste** que se deriva de utilizar $\\boldsymbol{\\theta}$ como estimador puntual de los parámetros. En relación con la dificultad del problema de optimización, indica cuál de las siguientes afirmaciones es incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Optimización global es por lo general más difícil que optimización local, si bien en ocasiones se puede garantizar que todo óptimo local es también global.\n",
    "2. Optimización con restricciones suele ser más difícil que optimización sin restricciones. No obstante, muchas veces podemos relajar (eliminar) restricciones, resolver el problema relajado y limitarnos a comprobar que la solución hallada cumple las restricciones relajadas.\n",
    "3. En general, dado un $\\,\\boldsymbol{\\theta}^*\\in\\mathbb{R}^D,\\,$ podemos determinar si se trata de un mínimo local mediante el gradiente del objetivo en $\\,\\boldsymbol{\\theta}^*$.\n",
    "4. Las tres opciones anteriores son correctas.\n",
    "\n",
    "<details><summary>Solución:</summary><br>\n",
    "\n",
    "La 3; el gradiente nulo en $\\,\\boldsymbol{\\theta}^*$ es condición necesaria pero no suficiente.\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Optimización:** $\\;$ Dada la función objetivo $\\mathcal{L}(\\theta)=\\theta^4,\\,$ aplica una iteración de descenso por gradiente a partir de $\\,\\theta_0=1\\,$ con factor de aprendizaje $\\,\\eta=0.1$.\n",
    "\n",
    "<details><summary>Solución:</summary><br>\n",
    "\n",
    "$$\\frac{d\\mathcal{L}(\\theta)}{d\\theta}=4\\,\\theta^3\\quad\\to\\quad\\theta_1=\\theta_0-0.1\\cdot 4\\cdot \\theta_0^3=1-0.4\\cdot 1^3=0.6$$\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Probabilidad:** $\\;$ La función de densidad de la Gaussiana $D$-dimensional es de la forma\n",
    "$$p(\\boldsymbol{y}\\mid\\boldsymbol{\\mu},\\mathbf{\\Sigma})=\\dfrac{1}{(2\\pi)^{D/2}\\det{\\mathbf{\\Sigma}}^{1/2}}%\n",
    "\\exp\\left[-\\dfrac{1}{2}(\\boldsymbol{y}-\\boldsymbol{\\mu})^t\\mathbf{\\Sigma}^{-1}(\\boldsymbol{y}-\\boldsymbol{\\mu})\\right], %\n",
    "\\quad\\boldsymbol{\\mu}\\mathbb{I}n\\mathbb{R}^D,\\;\\mathbf{\\Sigma}\\mathbb{I}n\\mathbb{R}^{D\\times D},\\;\\mathbf{\\Sigma}\\succeq 0$$\n",
    "Sus conjuntos de nivel son proporcionales a los de la distancia de Mahalanobis entre $\\boldsymbol{y}$ y $\\boldsymbol{\\mu}$. La forma de estos conjuntos, esto es, de la bola Gaussiana centrada en $\\boldsymbol{\\mu}$, depende de $\\mathbf{\\Sigma}$. Suponiendo que $D=2$, indica la respuesta incorrecta (o la última opción si las tres primeras son correctas).\n",
    "1. Si $\\mathbf{\\Sigma}=\\sigma^2\\mathbf{I}$, la Gaussiana es circular.\n",
    "2. Si $\\mathbf{\\Sigma}$ es diagonal, la Gaussiana es rectangular.\n",
    "3. Si $\\mathbf{\\Sigma}$ no es diagonal (con elementos no nulos fuera de la diagonal), la Gaussiana es elípitica.\n",
    "4. Las tres opciones anteriores son correctas.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 2; la Gaussiana es elípitica, de semiejes alineados con los canónicos.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadística:** $\\;$ Sea $\\,\\mathcal{D}=\\{(\\boldsymbol{x}_n,\\boldsymbol{y}_n)\\}_{n=1}^N\\,$ un conjunto de datos y sea $\\,p(\\mathcal{D}\\mid\\boldsymbol{\\theta})\\,$ la verosimilitud de un modelo gobernado por un vector de parámetros $\\,\\boldsymbol{\\theta}$. Supón que la verosimilitud puede factorizarse de manera naive como $p(\\mathcal{D}\\mid\\boldsymbol{\\theta})=\\prod_n p(\\boldsymbol{y}_n\\mid\\boldsymbol{x}_n,\\boldsymbol{\\theta})$. Con base en esta asunción, se quiere hallar un estimador máximo-verosímil de $\\boldsymbol{\\theta}$, $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}$. Indica la respuesta incorrecta (o la última opción si las tres primeras son correctas).\n",
    "1. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{y}_n\\mid\\boldsymbol{x}_n,\\boldsymbol{\\theta})$\n",
    "2. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{x}_n, \\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})-\\log p(\\boldsymbol{x}_n\\mid\\boldsymbol{\\theta})$\n",
    "3. $\\hat{\\boldsymbol{\\theta}}_{\\text{mle}}=\\operatorname{argmin}_{\\boldsymbol{\\theta}}-\\sum_n \\log p(\\boldsymbol{x}_n, \\boldsymbol{y}_n\\mid\\boldsymbol{\\theta})$\n",
    "4. Las tres opciones anteriores son correctas.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 3.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Estadística:** $\\;$ Uno de los grandes retos del aprendizaje automático consiste en aprender modelos que generalicen bien, esto es, que no se limiten a predecir correctamente los datos de entrenamiento, sino que también predigan bien datos futuros. Con el fin de afrontar este reto, se suelen seguir varias estrategias convencionales que por lo general dan buen resultado. Indica cuál de las siguientes estrategias **no** es una estrategia convencional para generalizar mejor (o escoge la última opción si las tres primeras sí lo son).\n",
    "1. Regularización.\n",
    "2. Terminación temprana (asumiendo que se usa un algoritmo de aprendizaje iterativo).\n",
    "3. Uso de más datos.\n",
    "4. Las tres opciones anteriores son estrategias convencionales para generalizar mejor.\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 4.</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Decisión:** $\\;$ En un problema de clasificación en $C$ clases, tanto los posibles estados de la naturaleza como las posibles acciones son etiquetas de clase, $\\,\\mathcal{H}=\\mathcal{A}=\\mathcal{Y}=\\{1,\\dotsc,C\\}$. Supón que la pérdida asociada a cada par estado-acción es la 01, $\\,\\ell(y^*,\\hat{y})=\\mathbb{I}(y^*\\neq\\hat{y}),\\,$ donde $\\,y^*\\,$ denota la clase verdadera y $\\hat{y}$ la predicha. Dada una observación $\\boldsymbol{x}$, el riesgo de una acción $\\,\\hat{y}\\,$ y la acción de mínimo riesgo (regla de Bayes) son:\n",
    "1. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*=\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmin}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "2. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*=\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "3. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*\\neq\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmin}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "4. $R(\\hat{y}\\mid\\boldsymbol{x})=1-p(y^*\\neq\\hat{y}\\mid\\boldsymbol{x})\\;$ y $\\;\\pi^*(\\boldsymbol{x})=\\operatorname{argmax}_{y\\in\\mathcal{Y}}\\;p(y\\mid\\boldsymbol{x})$\n",
    "\n",
    "<details><summary>Solución:</summary><br>La 2.</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
