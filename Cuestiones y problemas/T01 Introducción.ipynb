{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# T01 Introducción"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La aproximación probabilística al aprendizaje automático (ML) suele plantearse a partir de la definición de ML dada por Tom Mitchell en 1997: \"Un sistema (de ML) aprende de la experiencia E respecto a una clase de tareas T y una medida de rendimiento R, si su rendimiento en T, medido por R, mejora con E\". En relación con la forma de ML más común, el aprendizaje supervisado, indica cuál de las siguientes afirmaciones sobre E, T y R es incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. La tarea T consiste en aprender una transformación $f:\\mathcal{X}\\to\\mathcal{Y}$ con, usualmente, $\\mathcal{X}=\\mathbb{R}^D$ e $\\mathcal{Y}=\\{1,\\dotsc,C\\}$ (clasificación), o $\\mathcal{Y}=\\mathbb{R}$ (regresión).\n",
    "2. La experiencia E suele venir dada por un conjunto de $N$ datos, $\\mathcal{D}=\\{(\\boldsymbol{x}_n,\\boldsymbol{y}_n)\\}_{n=1}^N$; esto es, cada dato es un par entrada-salida, ejemplo de la transformación a aprender.\n",
    "3. La medida de rendimiento R depende del tipo salida; en general, se pretende que $f$ prediga bien los datos disponibles y, sobre todo, los futuros.\n",
    "4. Las tres afirmaciones anteriores son correctas.\n",
    "\n",
    "<details>\n",
    "Solución: la 4\n",
    "</details>"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
