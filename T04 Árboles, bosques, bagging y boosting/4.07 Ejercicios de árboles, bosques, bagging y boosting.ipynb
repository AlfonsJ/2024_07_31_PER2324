{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.01 Árboles de regresión y clasificación"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.01:** Los árboles de clasificación y regresión (CART) particionan el espacio de entrada recursivamente y definen un modelo local en cada región resultante; globalmente, el modelo és un árbol con una hoja por región. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. El árbol constituye un conjunto de reglas de decisión anidadas.\n",
    "2. Los nodos internos definen splits paralelos a los ejes.\n",
    "3. En cada hoja se especifica la salida predicha para toda entrada dentro de su región asociada.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.02:** Un árbol de regresión de $J$ hojas y parámetros $\\boldsymbol{\\theta}=\\{(R_j,w_j)\\}$ es $f(\\boldsymbol{x};\\boldsymbol{\\theta})=\\sum_{j=1}^Jw_j\\mathbb{I}(\\boldsymbol{x}\\in R_j)$, donde $R_j$ y $w_j$ denotan la región y salida asociadas a la hoja $j$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. $R_j$ se define a partir de las características y umbrales empleados en cada split, en el camino de la raíz a la hoja $j$.\n",
    "2. Con entradas categóricas, los splits pueden hacerse comparando la característica $d_i$ con cada uno de sus valores posibles.\n",
    "3. Si el árbol es de clasificación, cada hoja contiene una respuesta media.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 3; si el árbol es de clasificación, cada hoja contiene una distribución sobre las etiquetas de clase, no una respuesta media."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.03:** El ajuste de un árbol $f(\\boldsymbol{x};\\boldsymbol{\\theta})=\\sum_{j=1}^Jw_j\\mathbb{I}(\\boldsymbol{x}\\in R_j)$, $\\boldsymbol{\\theta}=\\{(R_j,w_j)\\}$, requiere minimizar la pérdida empírica\n",
    "$$\\mathcal{L}(\\boldsymbol{\\theta})=\\sum_{n=1}^N\\ell(y_n,f(\\boldsymbol{x}_n;\\boldsymbol{\\theta}))%\n",
    "=\\sum_{j=1}^J\\sum_{\\boldsymbol{x}_n\\in R_j}\\ell(y_n,w_j)$$\n",
    "Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. $\\mathcal{L}(\\boldsymbol{\\theta})$ no es diferenciable pues depende de la estructura del árbol.\n",
    "2. Hallar una estructura óptima del árbol es NP-Duro.\n",
    "3. La estructura del árbol se suele aprender mediante fusión de hojas a partir de un árbol con tantas hojas como datos.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 3; la  estructura del árbol se suele aprender con un método voraz como CART, C4.5 o ID3, que haga crecer el árbol añadiendo un nodo en cada iteración."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.04:** Los posibles splits de datos en un nodo $i$, $\\mathcal{D}_i=\\{(\\boldsymbol{x}_n,y_n)\\in N_i\\}$, dependen de la característica $j$ que se escoja. En general, se define un conjunto de valores de $j$, $\\mathcal{T}_j$, y por cada $t\\in\\mathcal{T}_j$ se considera una dicotomía de $\\mathcal{D}_i$ en un hijo izquierdo $\\mathcal{D}_i^L(j,t)$ y otro derecho $\\mathcal{D}_i^R(j,t)$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Si $j$ es real, $\\mathcal{T}_j$ se suele definir ordenando los valores únicos de $\\{x_{nj}\\}$; $\\mathcal{D}_i^L(j,t)$ incluye los datos de $i$ cuya característica $j$ no es mayor que $t$, mientras que el resto de datos va a $\\mathcal{D}_i^R(j,t)$.\n",
    "2. Si $j$ es categórica, $\\mathcal{T}_j$ se suele definir con todos sus valores posibles; $\\mathcal{D}_i^L(j,t)$ incluye los datos de $i$ cuya característica $j$ es igual a $t$, mientras que el resto de datos va a $\\mathcal{D}_i^R(j,t)$.\n",
    "3. Tanto si $j$ es real como si no, conviene excluir toda dicotomía que dé lugar a un hijo vacío.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.05:** El mejor par característica-valor para hacer el split de un nodo $i$, $(j_i,t_i)$, se elige usando una función coste de nodo, $c(\\mathcal{D}_i)$:\n",
    "$$(j_i,t_i)=\\operatorname*{argmin}_{j\\in\\{1,\\dotsc,D\\}}\\min_{t\\in\\mathcal{T}_j}%\n",
    "\\frac{\\lvert\\mathcal{D}_i^L(j,t)\\rvert}{\\lvert\\mathcal{D}_i\\rvert}\\,c(\\mathcal{D}_i^L(j,t))%\n",
    "+\\frac{\\lvert\\mathcal{D}_i^R(j,t)\\rvert}{\\lvert\\mathcal{D}_i\\rvert}\\,c(\\mathcal{D}_i^R(j,t))$$\n",
    "Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. En regresión se suele usar la pérdida 0-1, esto es, el nùmero de muestras mal clasificadas.\n",
    "2. En clasificación es popular el uso del índice Gini, que estima el error de clasificación esperado.\n",
    "3. En clasificación es popular el uso de la impureza, medida como entropía de la distribución empírica de les clases.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 1. En regresión se usa $c(\\mathcal{D}_i)=\\frac{1}{\\lvert\\mathcal{D}_i\\rvert}\\sum\\nolimits_{n\\in\\mathcal{D}_i}(y_n-\\bar{y})^2$, donde $\\bar{y}$ denota la respuesta media en el nodo; esto es, el error cuadrático medio. No tiene sentido hablar de muestras mal clasificadas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.06:** Si el árbol es demasiado grande, su ajuste puede conducir a sobre-entrenamiento, por lo que conviene aplicar alguna técnica de regularización que lo evite. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. El sobre-entrenamiento extremo produce error de entrenamiento nulo (sin ruido de etiquetas) tras particionar el espacio de entrada en regiones muy pequeñas de salida constante.\n",
    "2. Una técnica de regularización bien conocida consiste en parar el crecimiento con un heurístico, como tener pocos ejemplos en un nodo o alcanzar una profundidad máxima.\n",
    "3. Otra técnica de regularización consiste en dejar crecer el árbol al máximo y podarlo de hijos a padres mediante fusión de hijos.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.07:** A diferencia de otros modelos (como las redes), los árboles manejan bien características de entrada perdidas mediante heurísticos sencillos. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Si en test nos falta una variable, usamos splits surrogados, esto es, una variable sustituta que induzca particiones similares.\n",
    "2. Si dos o más características se hallan muy correladas en un mismo nodo, es de esperar que induzcan particiones diferentes.\n",
    "3. Con variables categóricas, se suele codificar \"perdido\" como nuevo valor y tratar los datos como completamente observados.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 2. Si dos o más características se hallan muy correladas en un mismo nodo, es de esperar que induzcan particiones similares, no diferentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.01.08:** Los árboles presentan una serie de ventajas e incovenientes que cabe tener presentes para su uso. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Son insensibles a transformaciones monótonas de las entradas ya que los puntos de split se basan en la ordenación de los datos, por lo que es necesario estandarizarlos.\n",
    "2. Son de ajuste rápido y fácil escalado a muchos datos.\n",
    "3. Son inestables, esto es, pequeños cambios en los datos de entrada pueden tener grandes cambios en la estructura del árbol.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 1. Al revés, no es necesario estandarizarlos por ser insensibles a transformaciones monótonas de las entradas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.02 Aprendizaje de ensambles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.02.01:** Los árboles constituyen un estimador de alta varianza ya que pequeñas perturbaciones de los datos de entrenamiento resultan en predicciones muy distintas. El aprendizaje de ensambles reduce la varianza de los árboles promediando $\\lvert\\mathcal{M}\\rvert$ modelos base $\\{f_m\\}$, $f(y\\mid\\boldsymbol{x})=\\frac{1}{\\lvert\\mathcal{M}\\rvert}\\sum\\nolimits_{m\\in\\mathcal{M}}f_m(y\\mid\\boldsymbol{x})$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. En regresión, el promediado suele presentar un sesgo similar al de los modelos base, pero mejor precisión por la menor varianza.\n",
    "2. En clasificación se usa el voto mayoritario o método comité, que incrementa la precisión de los modelos base, especialmente cuando sus errores de predicción se hallan correlados.\n",
    "3. La precisión de un comité de $M$ predictores independientes de probabilidad de acierto $\\theta$ puede calcularse fácilmente a partir de la función de distribución binomial como $p=1-B(M/2,M,\\theta)$.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 2. El comité incrementa la precisión de los modelos base sobre todo cuando los errores de los aprendices **no** se hallan correlados; si fuera al revés, podríamos mejorar la precisión haciendo copias de un mismo aprendiz."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.03 Bagging"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.03.01:** Bagging (bootstrap aggregating) ensambla $M$ modelos ajustados con diferentes versiones de los datos, obtenidas por boostraping (muestreo con reemplazamiento). Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Una desventaja es que cada modelo solo ve un $90\\%$ de datos aprox, si bien los datos no vistos pueden usarse en test.\n",
    "2. Una ventaja es que ofrece mayor robustez y generalización que ensamble pues no depende demasiado de ningún dato de entrenamiento individual.\n",
    "3. Aunque funciona bien con árboles, no suele mejorar la precisión de otros modelos como vecinos y redes.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 1; cada modelo ve un $63\\%$ de datos aprox, no un $90\\%$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.04 Random forests"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.04.01:** Los bosques aleatorios decorrelan los aprendices mediante aleatorización, no solo de los datos de entrenamiento, sino también de las variables de entrada. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. La aleatorización de variables se realiza a nivel de nodo: la característica de split $j_i$ de un nodo $i$ se optimiza sobre un subconjunto aleatorio $S_i\\subseteq\\{1,\\dotsc,D\\}$.\n",
    "2. En general, los bosques son más precisos que bagging ya que muchas características son irrelevantes.\n",
    "3. Al igual que boosting, el entrenamiento es esencialmente secuencial.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 3. Es cierto que el entrenamiento en boosting  es esencialmente secuencial. Sin embargo, los (aprendices de los) bosques pueden entrenarse en paralelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.05 Boosting"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.01:** Llamamos modelo aditivo al ensamble de funciones base aditivas generales, $f(\\boldsymbol{x};\\boldsymbol{\\theta})=\\sum\\nolimits_{m=1}^M\\beta_mF_m(\\boldsymbol{x};\\boldsymbol{\\theta}_m)$, ajustable mediante minimización de la pérdida empírica, $\\mathcal{L}(f)=\\sum\\nolimits_{i=1}^N\\ell(y_i,f(\\boldsymbol{x}_i))$. Boosting ajusta secuencialmente modelos aditivos de clasificadores binarios, $F_m\\in\\{-1,+1\\}$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Boosting ajusta $F_1$ y pondera los datos asignando mayor peso a los errores; luego ajusta $F_2$ a los datos ponderados, repondera, y repite ajuste y reponderación hasta llegar a $M$ componentes.\n",
    "2. El strong learner, $f$, mejora la precisión de los weak learners, $\\{F_m\\}$, si la precisión de cada uno de ellos es mejor que el azar.\n",
    "3. Boosting va mejor que bagging y bosques ya que reduce el sesgo de $f$ ajustando árboles que dependen unos de otros, en lugar de limitarse a reducir la varianza con árboles independientes.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.02:** Forward stagewise additive modeling (FSAM) optimiza la pérdida empírica con pérdida general y $f$ modelo aditivo. En la iteración $m$, calcula $(\\beta_m,\\boldsymbol{\\theta}_m)$ y reajusta modelo, $f_m(\\boldsymbol{x})=f_{m-1}(\\boldsymbol{x})+\\beta_mF(\\boldsymbol{x};\\boldsymbol{\\theta}_m)$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Aunque boosting se propuso en los 90 en el marco del aprendizaje PAC (probablemente aproximadamente correcto), poco después se interpretó de forma más general, bajo una visión estadística, como técnica FSAM.\n",
    "2. Una gran ventaja de FSAM es que permite reajustar parámetros de modelos base añadidos previamente.\n",
    "3. Los detalles de optimización dependen de la pérdida escogida y (en algunos casos) de la forma del aprendiz débil $F$.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 2. FSAM no reajusta parámetros de modelos base añadidos antes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.03:** A continuación se describen algunos algoritmos de boosting en relación con FSAM. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. Boosting mínimos cuadrados (L2Boost) es FSAM con pérdida 0-1, $\\ell(y,\\hat{y})=\\mathbb{I}(y\\neq\\hat{y})$.\n",
    "2. AdaBoost es FSAM para clasificación binaria, $\\tilde{y}_i\\in\\{-1,+1\\}$, con pérdida exponencial, $\\ell(\\tilde{y},F(\\boldsymbol{x}))=\\exp(-\\tilde{y}F(\\boldsymbol{x}))$.\n",
    "3. LogitBoost es FSAM para clasificación binaria, $\\tilde{y}_i\\in\\{-1,+1\\}$, con logloss, $\\ell(\\tilde{y},F(\\boldsymbol{x}))=\\log(1+e^{-2\\tilde{y}F(\\boldsymbol{x})})$.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 1. Boosting mínimos cuadrados (L2Boost) es FSAM con pérdida cuadrática, $\\ell(y,\\hat{y})=(y-\\hat{y})^2$."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.04:** Gradient boosting es FSAM, pero abandona la idea de reponderar datos iterativamente y lo plantea como descenso por gradiente para un problema de búsqueda en un espacio funcional, $\\hat{\\boldsymbol{f}}=\\operatorname{argmin}_{\\boldsymbol{f}}\\mathcal{L}(\\boldsymbol{f})$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. El paso $m$ halla $\\boldsymbol{f}_m=\\boldsymbol{f}_{m-1}-\\beta_m\\boldsymbol{g}_m$, donde $\\boldsymbol{g}_m$ es el gradiente de $\\mathcal{L}(\\boldsymbol{f})$ en $\\boldsymbol{f}=\\boldsymbol{f}_{m-1}$ y $\\beta_m$ se obtiene por búsqueda lineal.\n",
    "2. $\\boldsymbol{f}_m$ se obtiene añadiendo a $\\boldsymbol{f}_{m-1}$ un modelo base $F_m(\\boldsymbol{x})$ ajustado por mínimos cuadrados al residuo del gradiente.\n",
    "3. $\\beta_m$ suele sustituirse por un factor de reducción $0<\\nu\\leq 1$ que permite regularizar y, así, $f_m(\\boldsymbol{x})=f_{m-1}(\\boldsymbol{x})+\\nu F_m(\\boldsymbol{x})$.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.05:** Gradient boosting es un algoritmo genérico para pérdidas diferenciables diversas. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. BinomialBoost es gradient boosting con log-loss para clasificación binaria, como LogitBoost.\n",
    "2. Gradient boosting puede adaptarse a clasificación multiclase mediante un árbol de regresión separado por clase y una softmax para combinar predicciones.\n",
    "3. Stochastic gradient boosting consiste en submuestrear datos al azar en cada iteración para ajustar el modelo base.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.05.06:** Gradient tree boosting es gradient boosting con árbol de regresión como modelo base, $F_m(\\boldsymbol{x})=\\sum_{j=1}^{J_m}w_{jm}\\mathbb{I}(\\boldsymbol{x}\\in R_{jm})$. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. $R_{jm}$ se aprende con CART sobre residuos.\n",
    "2. $w_{jm}$ se aprende mediante minimización de la pérdida empírica con los datos en $R_{jm}$, $\\hat{w}_{jm}=\\operatorname{argmin}_w\\sum_{\\boldsymbol{x}_i\\in R_{jm}}\\ell(y_i,f_{m-1}(\\boldsymbol{x}_i)+w)$.\n",
    "3. En el caso de la pérdida cuadrática, $\\hat{w}_{jm}$ es el máximo de los residuos de la hoja $j$.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 3; es la media, no el máximo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.06 Interpretación de ensambles de árboles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**4.06.01:** La interpretabilidad de los árboles no se mantiene con sus ensambles en forma de bagging, random forests o boosting, si bien existen métodos sencillos para interpretar la función aprendida. Indica la respuesta incorrecta (o escoge la última opción si las tres primeras son correctas).\n",
    "1. La importancia de una característica $k$ en un árbol es la suma de las ganancias de los nodos internos que la usan; en el caso de un ensamble, se promedia la importancia en todos sus árboles.\n",
    "2. Un gráfico de dependencia parcial de un modelo muestra su predicción empírica en función de una característica o dos.\n",
    "3. En clasificación binaria, el gráfico de dependencia parcial se suele presentar con log-odds en lugar de predicción empírica.\n",
    "4. Todas son correctas."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solución:** La 4."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
