{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests\n",
    "\n",
    "**Random forests** puede verse como una variante de bagging de árboles que trata de mejorar la decorrelación de modelos base mediante aleatorización, no solo de los datos de entrenamiento, sino también de las variables de entrada. Así, la característica de split $j_i$ se optimiza sobre un conjunto aleatorio $S_i\\subseteq\\{1,\\dotsc,D\\}$,\n",
    "$$(j_i,t_i)=\\operatorname*{arg}\n",
    "\\min_{j\\in S_i}\\min_{t\\in\\mathcal{T}_j}\\;%\n",
    "\\frac{\\lvert\\mathcal{D}_i^L(j,t)\\rvert}{\\lvert\\mathcal{D}_i\\rvert}\\,c(\\mathcal{D}_i^L(j,t))+%\n",
    "\\frac{\\lvert\\mathcal{D}_i^R(j,t)\\rvert}{\\lvert\\mathcal{D}_i\\rvert}\\,c(\\mathcal{D}_i^R(j,t))$$\n",
    "En general, los bosques son más precisos que bagging ya que muchas características son irrelevantes. Por otro lado, los aprendices pueden entrenarse en paralelo, cosa que no puede hacerse con boosting.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo:** clasificación de correos en spam y no-spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF 10 trees, test err 6.3%\n",
      "RF 50 trees, test err 5.0%\n",
      "RF 100 trees, test err 4.9%\n",
      "RF 200 trees, test err 4.8%\n",
      "RF 300 trees, test err 4.9%\n",
      "RF 400 trees, test err 4.8%\n",
      "RF 500 trees, test err 4.8%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "df = pd.read_csv(\"https://github.com/empathy87/The-Elements-of-Statistical-Learning-Python-Notebooks/blob/master/data/Spam.txt?raw=True\")\n",
    "is_test = df.test.values; y = df.spam.values; X = df.drop(['test','spam'], axis=1).to_numpy(copy=True)\n",
    "X_train, X_test = X[is_test == 0], X[is_test == 1]\n",
    "y_train, y_test = y[is_test == 0], y[is_test == 1]\n",
    "ntrees_list = [10, 50, 100, 200, 300, 400, 500]\n",
    "for ntrees in ntrees_list:\n",
    "    clf = RandomForestClassifier(n_estimators=ntrees, random_state=10).fit(X_train, y_train)\n",
    "    y_test_hat = clf.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_test_hat)\n",
    "    print(f'RF {ntrees} trees, test err {1 - acc:.1%}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
